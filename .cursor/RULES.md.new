# CURSOR AI DEVELOPMENT RULES

## Table of Contents

1. [CRITICAL WORKFLOWS & PATTERNS](#1-critical-workflows--patterns)
2. [PROJECT IDENTITY & TECHNOLOGY STACK](#2-project-identity--technology-stack)
3. [NAMING CONVENTIONS & STANDARDS](#3-naming-conventions--standards)
4. [DATABASE & MIGRATIONS](#4-database--migrations)
5. [DOCKER & INFRASTRUCTURE](#5-docker--infrastructure)
6. [TRAEFIK & ROUTING](#6-traefik--routing)
7. [FRONTEND DEVELOPMENT (VUE 3)](#7-frontend-development-vue-3)
8. [API & MICROSERVICES](#8-api--microservices)
9. [TESTING & QUALITY ASSURANCE](#9-testing--quality-assurance)
10. [CI/CD & DEPLOYMENT](#10-cicd--deployment)
11. [VERSIONING & RELEASES](#11-versioning--releases)
12. [SECURITY & JWT](#12-security--jwt)
13. [OBSERVABILITY & MONITORING](#13-observability--monitoring)
14. [ARCHITECTURE & SYSTEM DESIGN](#14-architecture--system-design)
15. [TROUBLESHOOTING & DIAGNOSTICS](#15-troubleshooting--diagnostics)
16. [CURSOR AI SPECIFIC GUIDANCE](#16-cursor-ai-specific-guidance)

---

## 1. CRITICAL WORKFLOWS & PATTERNS

### 1.1 Code Synchronization (CRITICAL)

**CRITICAL RULE**: ALWAYS keep code synchronized between: Local Machine ↔ GitHub ↔ Server

**Workflow:**
- After ANY code changes: 1) Commit locally 2) Push to GitHub 3) Update server
- Server update: `ssh root@dating.serge.cc "cd /root/dating-microservices && git pull origin main && docker compose restart [affected-services]"`
- Never make changes directly on server - always go through Git workflow
- If server changes are needed, commit them locally first, then sync
- Verify synchronization: check git status, commit hashes, and service health on all three points

### 1.2 Git Workflow & Branch Strategy

**Branch Strategy:**
- All code changes must go through git: feature branch → commits → PR → review → merge → CI/CD rebuild
- Never modify files inside running containers or rely on manual hot-patches
- Use descriptive branch names: `feat/feature-name`, `fix/bug-description`, `refactor/component-name`
- Keep branches focused on single features or fixes
- Rebase feature branches on main before creating PR

**Commit Standards:**
- Use conventional commit messages: `<type>(scope): description`
- Include testing notes and deployment instructions in PR description

### 1.3 Conventional Commits

**Format:** `<type>(scope): description`

**Types:**
- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, etc.)
- `refactor`: Code refactoring
- `test`: Adding or updating tests
- `chore`: Maintenance tasks

**Scopes:**
- `bot`: Telegram bot changes
- `core`: Core library changes
- `gateway`: API Gateway changes
- `services`: Microservices changes
- `webapp`: Frontend changes
- `infra`: Infrastructure changes
- `docs`: Documentation changes

---

## 2. PROJECT IDENTITY & TECHNOLOGY STACK

### 2.1 Project Overview

This is a Telegram Mini App with an API Gateway and multiple Python microservices.

### 2.2 Core Technologies

**Backend Stack:**
- Python 3.11+
- aiogram 3.x (Telegram Bot API)
- aiohttp 3.9+ (HTTP server)
- SQLAlchemy 2.x (async ORM)
- asyncpg (PostgreSQL driver)
- Alembic (database migrations)
- PyJWT (JWT authentication)
- bcrypt (password hashing)

### 2.3 Infrastructure Stack

**Containerization:**
- Docker + Docker Compose
- Traefik 2.x (reverse proxy)
- PostgreSQL 15 (database)
- RabbitMQ (message queue)
- Redis (caching)

**Monitoring:**
- Prometheus (metrics)
- Grafana (visualization)
- Loki (log aggregation)
- cAdvisor (container metrics)
- Node Exporter (system metrics)

### 2.4 Frontend Stack

**Vue 3 + Vite + Pinia:**
- Vue 3.4+ (reactive framework)
- Vite 5.0+ (build tool)
- Pinia 2.1+ (state management)
- Vue Router 4.2+ (routing)
- Axios 1.6+ (HTTP client)
- Telegram WebApp SDK (integration)

### 2.5 Folder Layout & Architecture

**Required Structure:**
```
bot/                    # Telegram bot
core/                   # Shared libraries
gateway/               # API Gateway
services/              # Microservices
  ├── auth/           # Authentication service
  ├── profile/        # User profiles
  ├── discovery/      # Matching algorithm
  ├── chat/           # Messaging
  ├── media/          # File handling
  ├── admin/          # Admin panel
  ├── notification/   # Push notifications
  └── data/           # Data service
webapp/               # Frontend (Vue 3)
monitoring/           # Monitoring configs
migrations/            # Database migrations
scripts/              # Utility scripts
```

**CRITICAL**: Never hardcode ports. Use envs from .env/.env.example and docker-compose

---

## 3. NAMING CONVENTIONS & STANDARDS

### 3.1 Migration Naming & Management

**Standard Approach:**
- Use full filename as revision ID (e.g., `"007_create_chat_tables"`)
- Use descriptive filenames like `007_create_chat_tables.py` for readability

**Anti-patterns:**
- Manual revision ID changes after migration is in main branch
- Short numeric IDs like `"007"` (causes conflicts)
- Renaming migrations to `.bak` - Alembic won't see them

### 3.2 API Route Naming

**Pattern:** `/v1/{service}/{resource}/{action}`

**Examples:**
- `/v1/auth/login`
- `/v1/profiles/{user_id}`
- `/v1/discovery/swipe`
- `/v1/chat/messages`

### 3.3 Docker Service & Network Naming

**Service Naming:**
- Pattern: `{service-name}-service`
- Examples: `auth-service`, `profile-service`, `chat-service`

**Network Naming:**
- `default` (main application network)
- `monitoring` (monitoring services)

### 3.4 Environment Variables Naming

**Pattern:** `{SERVICE}_{CONFIG}_{OPTION}`

**Examples:**
- `POSTGRES_DB`, `POSTGRES_USER`, `POSTGRES_PASSWORD`
- `JWT_SECRET`, `ADMIN_PASSWORD`
- `AUTH_SERVICE_PORT`, `PROFILE_SERVICE_PORT`

### 3.5 File & Component Naming

**Python Files:**
- snake_case: `user_service.py`, `auth_middleware.py`

**Vue Components:**
- PascalCase: `UserProfile.vue`, `ChatMessage.vue`

**Database Tables:**
- snake_case: `user_profiles`, `chat_messages`

---

## 4. DATABASE & MIGRATIONS

### 4.1 Migration Workflow Rules

**New Migrations:**
- Use `alembic revision -m "descriptive message"` (auto-generates hash)
- Keep descriptive filenames for human readability
- Never manually edit revision IDs after migration is committed to main

**Database Version:**
- Check with `SELECT version_num FROM alembic_version;`
- RUN_DB_MIGRATIONS: Set to `true` only for one service (usually telegram-bot)

### 4.2 Migration Conflict Resolution

**Before Merging:**
- Always run `alembic check` to verify migration chain
- Use `alembic merge -m "merge message"` to create merge migration
- Never manually edit `down_revision` in existing migrations

**PR Checklist:**
- [ ] Migration file has descriptive name
- [ ] Revision ID is full filename (not manually edited)
- [ ] `down_revision` points to correct previous migration
- [ ] Run `alembic check` - no errors
- [ ] Test migration locally: `alembic upgrade head`
- [ ] Test rollback: `alembic downgrade -1` then `alembic upgrade head`
- [ ] No `.bak` files in migrations/versions/
- [ ] Migration is reversible (has both `upgrade()` and `downgrade()`)

### 4.3 Emergency Migration Procedures

**Broken Migration Chain:**
- Use `alembic stamp <revision>` to reset to known good state
- Never skip migrations - always create proper merge migration
- Have rollback plan ready before applying migrations

**Database Corruption:**
- Restore from backup, then reapply migrations in order

### 4.4 Common Migration Commands

```bash
# Create new migration
alembic revision -m "descriptive message"

# Check migration chain integrity
alembic check

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# Rollback to specific revision
alembic downgrade <revision>

# Merge conflicting migrations
alembic merge -m "merge message" <revision1> <revision2>

# Reset to specific revision (emergency only)
alembic stamp <revision>

# Show current revision
alembic current

# Show migration history
alembic history
```

### 4.5 SQLAlchemy Best Practices

**Use SQLAlchemy 2.0 ORM (async):**
- Use explicit `select()` API
- Avoid legacy 1.x patterns
- Use explicit transactions with async sessions
- One session per request when needed

**Database Connections:**
- Use connection pooling
- Handle connection timeouts gracefully
- Implement retry logic for transient failures

---

## 5. DOCKER & INFRASTRUCTURE

### 5.1 Docker Security Standards

**Base Images:**
- MUST be pinned with specific versions (e.g., `python:3.11.7-slim`, not `python:3.11-slim`)
- Prefer distroless or slim variants to minimize attack surface
- Use multi-stage builds to minimize final image size

**Security Options:**
```yaml
security_opt:
  - no-new-privileges:true
cap_drop:
  - ALL
cap_add:
  - CHOWN
  - FOWNER
  - SETGID  # For Nginx
  - SETUID  # For some services
```

**Read-Only Root Filesystem:**
```yaml
read_only: true
tmpfs:
  - /tmp:rw,noexec,nosuid,size=100m
  - /app/cache:rw,noexec,nosuid,size=50m
  - /app/logs:rw,noexec,nosuid,size=100m
  - /var/run:rw,noexec,nosuid,size=10m
```

### 5.2 Docker User Standards

**CRITICAL RULE: ALL services MUST run as non-root user for security**

**Python Services (appuser):**
```dockerfile
# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Set proper permissions
RUN chown -R appuser:appuser /app

# Switch to non-root user
USER appuser
```

**Web Services (appuser for Nginx):**
```dockerfile
# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Set permissions for nginx
RUN chown -R appuser:appuser /var/cache/nginx /var/log/nginx /var/run/nginx

# Switch to non-root user
USER appuser
```

**Nginx Configuration for Non-Root:**
```nginx
# Run nginx as non-root user
user appuser;
worker_processes auto;

# Use writable directories
pid /var/run/nginx.pid;
error_log /var/log/nginx/error.log;
access_log /var/log/nginx/access.log;

# Use tmpfs for writable directories
```

**Database Services:**
- PostgreSQL: Use built-in `postgres` user
- RabbitMQ: Use built-in `rabbitmq` user

**Monitoring Services:**
- Prometheus: Use built-in `nobody` user
- Grafana: Use built-in `grafana` user
- cAdvisor: Use built-in `root` user (required for container access)

### 5.3 Docker Compose Patterns

**Health Checks:**
```yaml
healthcheck:
  test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health').read()"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

**Restart Policies:**
```yaml
restart: unless-stopped
```

**Resource Limits:**
```yaml
deploy:
  resources:
    limits:
      cpus: '0.5'
      memory: 512M
    reservations:
      cpus: '0.25'
      memory: 256M
```

### 5.4 Environment Management

**Environment Detection:**
- Use `ENVIRONMENT=development|production` to distinguish
- Monitoring stack: Prometheus, Grafana, Loki ONLY on production
- Development: `docker compose up -d` (no monitoring)
- Production: `docker compose --profile production up -d` (with monitoring)

**Environment Configuration:**
- Local development: Use `.env` file with `ENVIRONMENT=development`
- Production server: Use `.env` file with `ENVIRONMENT=production`
- Required variables: `BOT_TOKEN`, `JWT_SECRET`, `POSTGRES_PASSWORD`
- Environment-specific: Different domains, SSL, monitoring

### 5.5 Docker Network Configuration

**Network Isolation:**
```yaml
services:
  api-gateway:
    networks:
      - frontend
      - backend
    # No external port exposure for internal services
    
  database:
    networks:
      - backend
    # No external port exposure
```

**Internal Communication:**
```yaml
# Use internal service names
environment:
  DATABASE_URL: postgresql://db:5432/dating
  REDIS_URL: redis://redis:6379
  AUTH_SERVICE_URL: http://auth-service:8081
```

### 5.6 Health Checks & Restart Policies

**Health Check Pattern:**
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://127.0.0.1:80/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

**Health Endpoint Implementation:**
```python
async def health_check(request: web.Request) -> web.Response:
    """Health check endpoint."""
    try:
        # Check database connectivity
        await check_database()
        
        # Check external dependencies
        await check_dependencies()
        
        return web.json_response({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "version": "1.2.0"
        })
    except Exception as e:
        return web.json_response({
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }, status=503)
```

### 5.7 Secrets Management

**Environment Variables:**
```yaml
services:
  api-gateway:
    environment:
      - JWT_SECRET=${JWT_SECRET}
      - DATABASE_URL=${DATABASE_URL}
    # Never use secrets in docker-compose.yml directly
```

**Docker Secrets (Production):**
```yaml
services:
  api-gateway:
    secrets:
      - jwt_secret
      - database_password
    environment:
      - JWT_SECRET_FILE=/run/secrets/jwt_secret
      - DATABASE_PASSWORD_FILE=/run/secrets/database_password

secrets:
  jwt_secret:
    external: true
  database_password:
    external: true
```

---

## 6. TRAEFIK & ROUTING

### 6.1 Traefik Configuration Patterns

**Route Labels:**
```yaml
labels:
  - "traefik.http.routers.{service}.rule=Host(`${DOMAIN:-localhost}`) && PathPrefix(`/path`)"
  - "traefik.http.routers.{service}.entrypoints=web"
  - "traefik.http.routers.{service}.priority=1"
  - "traefik.http.services.{service}.loadbalancer.server.port=8080"
```

### 6.2 Route Priority Matrix

**Priority Order:**
1. Webapp (priority 1)
2. Admin (priority 50)
3. API Direct (priority 100)
4. API Strip (priority 200)
5. Health (priority 300)
6. Metrics (priority 400)

### 6.3 Middleware Stack

**Standard Middleware:**
- `strip-prefix`: Remove path prefixes
- `headers`: Add security headers
- `rate-limit`: Rate limiting
- `redirect-to-https`: HTTP to HTTPS redirect

### 6.4 SSL/TLS Configuration

**Let's Encrypt:**
```yaml
labels:
  - "traefik.http.routers.{service}-secure.rule=Host(`${DOMAIN:-localhost}`)"
  - "traefik.http.routers.{service}-secure.entrypoints=websecure"
  - "traefik.http.routers.{service}-secure.tls.certresolver=letsencrypt"
```

### 6.5 Route Testing Commands

```bash
# Test HTTP route
curl -H "Host: dating.serge.cc" http://localhost/api/health

# Test HTTPS route
curl -H "Host: dating.serge.cc" https://localhost/api/health

# Test with specific path
curl -H "Host: dating.serge.cc" http://localhost/v1/auth/health
```

---

## 7. FRONTEND DEVELOPMENT (VUE 3)

### 7.1 Technology Stack

**Core Technologies:**
- Vue 3.4+ (reactive framework with Composition API)
- Vite 5.0+ (fast build tool and development server)
- Pinia 2.1+ (state management library)
- Vue Router 4.2+ (client-side routing)
- Axios 1.6+ (HTTP client for API communication)

**Development Tools:**
- @vitejs/plugin-vue (Vue SFC support for Vite)
- Terser (JavaScript minification)
- ESLint (code linting)
- Prettier (code formatting)

### 7.2 Project Structure

```
webapp/
├── src/
│   ├── components/          # Reusable Vue components
│   │   ├── common/          # Generic UI components
│   │   ├── chat/           # Chat-specific components
│   │   ├── discovery/      # Discovery/swipe components
│   │   ├── onboarding/     # Onboarding flow components
│   │   └── profile/        # Profile management components
│   ├── composables/        # Reusable composition functions
│   ├── stores/            # Pinia stores
│   ├── router/            # Vue Router configuration
│   ├── views/             # Page components
│   ├── utils/             # Utility functions
│   └── assets/            # Static assets
├── public/                # Public static files
├── index.html             # Entry HTML file
├── vite.config.js         # Vite configuration
└── package.json           # Dependencies and scripts
```

### 7.3 Vue 3 Component Standards

**Single File Component Structure:**
```vue
<template>
  <div class="component-name">
    <h1>{{ title }}</h1>
    <button @click="handleClick">Click me</button>
  </div>
</template>

<script setup>
import { ref, computed, onMounted } from 'vue'
import { useUserStore } from '@/stores/user'

// Props definition
const props = defineProps<{
  title: string
  isActive?: boolean
}>()

// Emits definition
const emit = defineEmits<{
  click: [payload: { id: string }]
}>()

// Reactive state
const count = ref(0)
const userStore = useUserStore()

// Computed properties
const doubleCount = computed(() => count.value * 2)

// Methods
const handleClick = () => {
  count.value++
  emit('click', { id: 'button' })
}

// Lifecycle
onMounted(() => {
  console.log('Component mounted')
})
</script>

<style scoped>
.component-name {
  padding: 1rem;
}
</style>
```

**Composition API Best Practices:**
```javascript
// Reactive state
const count = ref(0)
const message = ref('Hello')

// Reactive objects
const user = reactive({
  name: '',
  email: ''
})

// Computed properties
const fullName = computed(() => `${user.firstName} ${user.lastName}`)

// Watchers
watch(count, (newValue, oldValue) => {
  console.log(`Count changed from ${oldValue} to ${newValue}`)
})

// Lifecycle hooks
onMounted(() => {
  // Component mounted
})

onUnmounted(() => {
  // Cleanup
})
```

**Component Naming:**
- PascalCase: `UserProfile.vue`, `ChatMessage.vue`
- Descriptive names that indicate purpose
- Use kebab-case in templates: `<user-profile>`

### 7.4 Pinia State Management

**Store Structure:**
```javascript
// stores/user.js
import { defineStore } from 'pinia'
import { ref, computed } from 'vue'
import { useApi } from '@/composables/useApi'

export const useUserStore = defineStore('user', () => {
  // State
  const user = ref(null)
  const isLoading = ref(false)
  const error = ref(null)

  // Getters
  const isAuthenticated = computed(() => !!user.value)
  const userName = computed(() => user.value?.name || 'Guest')

  // Actions
  const fetchUser = async () => {
    try {
      isLoading.value = true
      error.value = null
      const response = await useApi().get('/user/profile')
      user.value = response.data
    } catch (err) {
      error.value = err.message
    } finally {
      isLoading.value = false
    }
  }

  const updateUser = async (userData) => {
    try {
      isLoading.value = true
      const response = await useApi().put('/user/profile', userData)
      user.value = response.data
    } catch (err) {
      error.value = err.message
    } finally {
      isLoading.value = false
    }
  }

  const logout = () => {
    user.value = null
  }

  return {
    // State
    user,
    isLoading,
    error,
    // Getters
    isAuthenticated,
    userName,
    // Actions
    fetchUser,
    updateUser,
    logout
  }
})
```

**Store Usage in Components:**
```vue
<script setup>
import { useUserStore } from '@/stores/user'
import { storeToRefs } from 'pinia'

const userStore = useUserStore()

// Destructure reactive state
const { user, isLoading, error } = storeToRefs(userStore)

// Use actions
const handleUpdate = () => {
  userStore.updateUser({ name: 'New Name' })
}
</script>
```

### 7.5 Vue Router Configuration

**Route Structure:**
```javascript
// router/index.js
import { createRouter, createWebHistory } from 'vue-router'
import { useUserStore } from '@/stores/user'

const routes = [
  {
    path: '/',
    name: 'Home',
    component: () => import('../views/HomeView.vue')
  },
  {
    path: '/profile',
    name: 'Profile',
    component: () => import('../views/ProfileView.vue'),
    meta: { requiresAuth: true }
  },
  {
    path: '/chat/:conversationId',
    name: 'Chat',
    component: () => import('../views/ChatView.vue'),
    meta: { requiresAuth: true }
  }
]

const router = createRouter({
  history: createWebHistory(),
  routes
})

// Navigation guards
router.beforeEach((to, from, next) => {
  const userStore = useUserStore()
  
  if (to.meta.requiresAuth && !userStore.isAuthenticated) {
    next('/login')
  } else {
    next()
  }
})

export default router
```

### 7.6 Composables & Reusable Logic

**API Composable:**
```javascript
// composables/useApi.js
import axios from 'axios'
import { ref } from 'vue'

export function useApi() {
  const isLoading = ref(false)
  const error = ref(null)

  const api = axios.create({
    baseURL: import.meta.env.VITE_API_BASE_URL,
    timeout: 10000
  })

  // Request interceptor
  api.interceptors.request.use((config) => {
    isLoading.value = true
    error.value = null
    
    // Add JWT token if available
    const token = localStorage.getItem('jwt_token')
    if (token) {
      config.headers.Authorization = `Bearer ${token}`
    }
    
    return config
  })

  // Response interceptor
  api.interceptors.response.use(
    (response) => {
      isLoading.value = false
      return response
    },
    (err) => {
      isLoading.value = false
      error.value = err.response?.data?.message || err.message
      return Promise.reject(err)
    }
  )

  return {
    api,
    isLoading,
    error
  }
}
```

**WebSocket Composable:**
```javascript
// composables/useWebSocket.js
import { ref, onMounted, onUnmounted } from 'vue'

export function useWebSocket(url) {
  const socket = ref(null)
  const isConnected = ref(false)
  const messages = ref([])

  const connect = () => {
    socket.value = new WebSocket(url)
    
    socket.value.onopen = () => {
      isConnected.value = true
    }
    
    socket.value.onmessage = (event) => {
      const message = JSON.parse(event.data)
      messages.value.push(message)
    }
    
    socket.value.onclose = () => {
      isConnected.value = false
    }
  }

  const sendMessage = (message) => {
    if (socket.value && isConnected.value) {
      socket.value.send(JSON.stringify(message))
    }
  }

  const disconnect = () => {
    if (socket.value) {
      socket.value.close()
    }
  }

  onMounted(() => {
    connect()
  })

  onUnmounted(() => {
    disconnect()
  })

  return {
    isConnected,
    messages,
    sendMessage,
    connect,
    disconnect
  }
}
```

### 7.7 Telegram WebApp Integration

**Telegram WebApp SDK:**
```javascript
// composables/useTelegram.js
import { ref, computed } from 'vue'

export function useTelegram() {
  const tg = window.Telegram.WebApp
  const user = ref(tg.initDataUnsafe.user)
  const theme = ref(tg.themeParams)

  const isExpanded = computed(() => tg.isExpanded)
  const platform = computed(() => tg.platform)

  const sendData = (data) => {
    tg.sendData(JSON.stringify(data))
  }

  const close = () => {
    tg.close()
  }

  const expand = () => {
    tg.expand()
  }

  const showAlert = (message) => {
    tg.showAlert(message)
  }

  const showConfirm = (message) => {
    return tg.showConfirm(message)
  }

  return {
    user,
    theme,
    isExpanded,
    platform,
    sendData,
    close,
    expand,
    showAlert,
    showConfirm
  }
}
```

### 7.8 Build & Deployment

**Vite Configuration:**
```javascript
// vite.config.js
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  plugins: [vue()],
  build: {
    outDir: 'dist',
    assetsDir: 'assets',
    sourcemap: false,
    minify: 'terser',
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['vue', 'vue-router', 'pinia'],
          telegram: ['@twa-dev/sdk']
        }
      }
    }
  },
  server: {
    port: 3000,
    host: true
  }
})
```

**Build Commands:**
```bash
# Development server
npm run dev

# Production build
npm run build

# Preview production build
npm run preview

# Type checking
npm run type-check

# Linting
npm run lint
```

**Environment Variables:**
```bash
# .env.local
VITE_API_BASE_URL=https://api.dating.serge.cc
VITE_WS_URL=wss://api.dating.serge.cc/ws
VITE_APP_NAME=Dating App
```

---

## 8. API & MICROSERVICES

### 8.1 API Gateway Patterns

**Route Configuration:**
```python
# Gateway routing
app.router.add_route("*", r"/v1/auth/{tail:.*}", route_auth)
app.router.add_route("*", r"/v1/profiles/{tail:.*}", route_profile)
app.router.add_route("*", r"/v1/discovery/{tail:.*}", route_discovery)
```

**Proxy Pattern:**
```python
async def proxy_request(request, target_url, path_override=None):
    # Strip prefix and proxy to target service
    new_path = path_override or request.path
    target = f"{target_url}{new_path}"
    # Proxy logic
```

### 8.2 Service Communication

**HTTP Communication:**
- Use aiohttp for async HTTP requests
- Implement retry logic with exponential backoff
- Handle timeouts gracefully

**Message Queue (RabbitMQ):**
- Use for async communication between services
- Implement dead letter queues for failed messages
- Use correlation IDs for request tracing

### 8.3 JWT Authentication & Middleware

**JWT Middleware:**
```python
async def jwt_middleware(request, handler):
    # Extract JWT from Authorization header
    auth_header = request.headers.get('Authorization')
    if not auth_header or not auth_header.startswith('Bearer '):
        raise web.HTTPUnauthorized()
    
    token = auth_header.split(' ')[1]
    # Verify JWT token
    payload = jwt.decode(token, JWT_SECRET, algorithms=['HS256'])
    request['user_id'] = payload['user_id']
    return await handler(request)
```

### 8.4 Error Handling Standards

**Error Response Format:**
```json
{
  "error": "error_code",
  "message": "Human readable message",
  "details": {
    "field": "validation error"
  },
  "timestamp": "2025-01-24T10:30:00Z"
}
```

**HTTP Status Codes:**
- 200: Success
- 400: Bad Request
- 401: Unauthorized
- 403: Forbidden
- 404: Not Found
- 422: Validation Error
- 500: Internal Server Error

### 8.5 Rate Limiting & Security

**Rate Limiting:**
```python
# Rate limiting middleware
async def rate_limiting_middleware(request, handler):
    client_ip = request.remote
    if await is_rate_limited(client_ip):
        raise web.HTTPTooManyRequests()
    return await handler(request)
```

**Security Headers:**
```python
# Security headers middleware
async def security_headers_middleware(request, handler):
    response = await handler(request)
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'DENY'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    return response
```

### 8.6 API Documentation Standards

**OpenAPI Specification:**
```yaml
openapi: 3.0.0
info:
  title: Dating App API
  version: 1.0.0
paths:
  /v1/auth/login:
    post:
      summary: User login
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                username:
                  type: string
                password:
                  type: string
```

---

## 9. TESTING & QUALITY ASSURANCE

### 9.1 Testing Standards (pytest)

**Test Structure:**
```python
# tests/test_auth.py
import pytest
from aiohttp import web
from services.auth.main import create_app

@pytest.fixture
async def client():
    app = create_app()
    async with aiohttp_client(app) as client:
        yield client

async def test_login_success(client):
    response = await client.post('/auth/login', json={
        'username': 'test',
        'password': 'password'
    })
    assert response.status == 200
    data = await response.json()
    assert 'token' in data
```

**Test Categories:**
- Unit tests: Test individual functions
- Integration tests: Test service interactions
- E2E tests: Test complete workflows

### 9.2 Code Quality Tools

**Black (Code Formatting):**
```bash
# Format code
black .

# Check formatting
black --check --diff .
```

**Ruff (Linting):**
```bash
# Lint code
ruff check .

# Auto-fix issues
ruff check --fix .
```

**MyPy (Type Checking):**
```bash
# Type check
mypy core/ services/ gateway/
```

**isort (Import Sorting):**
```bash
# Sort imports
isort .

# Check import order
isort --check-only --diff .
```

### 9.3 Pre-commit Hooks

**Configuration (.pre-commit-config.yaml):**
```yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
  - repo: https://github.com/charliermarsh/ruff-pre-commit
    rev: v0.0.270
    hooks:
      - id: ruff
        args: [--fix]
```

**Installation:**
```bash
# Install pre-commit
pip install pre-commit

# Install hooks
pre-commit install

# Run on all files
pre-commit run --all-files
```

### 9.4 CI Static Checks

**GitHub Actions:**
```yaml
- name: Run Black (code formatting)
  run: black --check --diff .

- name: Run Ruff (linting)
  run: ruff check .

- name: Run MyPy (type checking)
  run: mypy core/ services/ gateway/

- name: Run Bandit (security)
  run: bandit -r . -f json -o bandit-report.json
```

### 9.5 Coverage Requirements

**Coverage Threshold:**
- Minimum 80% code coverage
- Enforced in CI pipeline
- Exclude migrations and test files

**Coverage Commands:**
```bash
# Run tests with coverage
pytest --cov=core --cov=services --cov=gateway

# Generate coverage report
pytest --cov=core --cov-report=html
```

---

## 10. CI/CD & DEPLOYMENT

### 10.1 GitHub Actions Workflows

**Test Workflow:**
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest
```

**Static Checks Workflow:**
```yaml
name: Static Checks
on: [push, pull_request]
jobs:
  static-checks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      - name: Run Black (code formatting)
        run: black --check --diff .
      - name: Run isort (import sorting)
        run: isort --check-only --diff .
      - name: Run Ruff (linting)
        run: ruff check .
      - name: Run MyPy (type checking)
        run: mypy core/ services/ gateway/
      - name: Run Bandit (security)
        run: bandit -r . -f json -o bandit-report.json
```

**Docker Build Workflow:**
```yaml
name: Docker Build
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [auth-service, profile-service, discovery-service, media-service, chat-service, api-gateway, telegram-bot]
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: docker build -t ${{ matrix.service }} ./services/${{ matrix.service }}
```

### 10.2 CI Migration Safety Checks

**Migration Validation:**
```bash
# Check migration chain integrity
alembic check

# Validate only one service has RUN_DB_MIGRATIONS=true
grep -c "RUN_DB_MIGRATIONS=true" docker-compose.yml
```

**Migration Safety Script:**
```bash
#!/bin/bash
# scripts/validate-migration-safety.sh

# Check that only one service has RUN_DB_MIGRATIONS=true
MIGRATION_COUNT=$(grep -c "RUN_DB_MIGRATIONS=true" docker-compose.yml)
if [ "$MIGRATION_COUNT" -ne 1 ]; then
    echo "ERROR: Exactly one service must have RUN_DB_MIGRATIONS=true, found $MIGRATION_COUNT"
    exit 1
fi

# Check migration chain integrity
docker compose exec telegram-bot alembic check
if [ $? -ne 0 ]; then
    echo "ERROR: Migration chain integrity check failed"
    exit 1
fi

echo "Migration safety checks passed"
```

### 10.3 Pre-Deployment Checklist

**Code Quality:**
- [ ] All tests pass
- [ ] Code coverage meets threshold (80%+)
- [ ] No linting errors (Black, Ruff, MyPy)
- [ ] No security vulnerabilities (Bandit)
- [ ] Migration chain integrity verified

**Configuration:**
- [ ] Environment variables documented
- [ ] Dependencies updated in requirements.txt
- [ ] Docker images pinned to specific versions
- [ ] Health checks implemented for all services
- [ ] Security options applied (no-new-privileges, cap_drop)

**Infrastructure:**
- [ ] Docker Compose configuration validated
- [ ] Network configuration correct
- [ ] Resource limits set appropriately
- [ ] Monitoring stack configured (production only)

### 10.4 Deployment Process

**Local Development:**
```bash
# Start development environment
docker compose up -d

# Check service status
docker compose ps

# View logs
docker compose logs -f
```

**Production Deployment:**
```bash
# Deploy with monitoring
docker compose --profile production up -d

# Verify deployment
docker compose ps
curl -f https://dating.serge.cc/health
```

**Deployment Verification:**
```bash
# Check all services are healthy
docker compose ps | grep -v "healthy"

# Test critical endpoints
curl -f https://dating.serge.cc/health
curl -f https://dating.serge.cc/v1/auth/health
curl -f https://dating.serge.cc/v1/profiles/health
```

### 10.5 Post-Deployment Verification

**Service Status:**
```bash
# Check container status
docker compose ps

# Check service health
curl http://localhost:8080/health
curl http://localhost:8081/health
curl http://localhost:8082/health
```

**Database Verification:**
```bash
# Check migration status
docker compose exec telegram-bot alembic current

# Verify database connectivity
docker compose exec db psql -U dating -d dating -c "SELECT 1"

# Check database tables
docker compose exec db psql -U dating -d dating -c "\dt"
```

**Monitoring Verification:**
```bash
# Check Prometheus targets
curl http://localhost:9090/api/v1/targets

# Check Grafana dashboard
curl http://localhost:3001/api/health

# Check Loki logs
curl http://localhost:3100/ready
```

### 10.6 Rollback Procedures

**Emergency Rollback:**
```bash
# Rollback to previous version
git checkout HEAD~1
docker compose up -d

# Database rollback (if needed)
docker compose exec telegram-bot alembic downgrade -1

# Verify rollback
docker compose ps
curl -f https://dating.serge.cc/health
```

**Gradual Rollback:**
```bash
# Rollback specific service
docker compose stop <service>
docker compose up -d <service>

# Monitor service health
docker compose logs -f <service>
```

### 10.7 Deployment Automation

**GitHub Actions Deployment:**
```yaml
name: Deploy to Production
on:
  push:
    branches: [main]
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Deploy to server
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /root/dating-microservices
            git pull origin main
            docker compose down
            docker compose --profile production up -d
            docker compose ps
```

### 10.8 Environment Management

**Development Environment:**
- No monitoring stack
- Hot reload for development
- Local database
- Debug logging enabled

**Production Environment:**
- Full monitoring stack (Prometheus, Grafana, Loki)
- SSL/TLS encryption
- Production database
- Optimized logging
- Resource limits applied

---

## 11. VERSIONING & RELEASES

### 11.1 Semantic Versioning

**Version Format:** `vMAJOR.MINOR.PATCH`
- **MAJOR**: Breaking changes (API changes, database schema changes)
- **MINOR**: New features (backward compatible)
- **PATCH**: Bug fixes (backward compatible)

**Version Examples:**
```
v1.0.0  - Initial release
v1.1.0  - New feature: JWT refresh tokens
v1.1.1  - Bug fix: resolve auth timeout
v1.2.0  - New feature: admin panel
v2.0.0  - Breaking: API v2, new database schema
```

**Pre-release Versions:**
```
v1.2.0-alpha.1    - Alpha release
v1.2.0-beta.1     - Beta release
v1.2.0-rc.1       - Release candidate
v1.2.0            - Final release
```

### 11.2 Release Process

**Development Workflow:**
```bash
# Feature development
git checkout -b feature/jwt-refresh
# ... make changes ...
git commit -m "feat(auth): add JWT refresh endpoint"
git push origin feature/jwt-refresh

# Create PR, review and merge to main
```

**Automated Release Process:**
```yaml
# .github/workflows/release.yml
name: Release
on:
  push:
    branches: [main]
    tags: [v*]

jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Git
        run: |
          git config --global user.name "Release Bot"
          git config --global user.email "bot@dating.serge.cc"
      
      - name: Generate Changelog
        run: |
          git cliff --output CHANGELOG.md
          git add CHANGELOG.md
          git commit -m "chore: update changelog" || exit 0
      
      - name: Create Release
        uses: actions/create-release@v1
        with:
          tag_name: ${{ github.ref_name }}
          release_name: Release ${{ github.ref_name }}
          body_path: CHANGELOG.md
          draft: false
          prerelease: ${{ contains(github.ref_name, 'alpha') || contains(github.ref_name, 'beta') || contains(github.ref_name, 'rc') }}
```

### 11.3 Changelog Generation (git-cliff)

**Configuration (cliff.toml):**
```toml
[changelog]
header = "## Changelog"
body = """
## [{{version}}] - {{date}}
{% for group, commits in commits | group_by(attribute="group") %}
### {{ group | title }}
{% for commit in commits %}
- {{ commit.message | title }}
{% endfor %}
{% endfor %}
"""

[git]
conventional_commits = true
filter_unconventional = true
split_commits = true
commit_parsers = [
    { message = "^feat", group = "Features" },
    { message = "^fix", group = "Bug Fixes" },
    { message = "^docs", group = "Documentation" },
    { message = "^style", group = "Styling" },
    { message = "^refactor", group = "Code Refactoring" },
    { message = "^test", group = "Tests" },
    { message = "^chore", group = "Miscellaneous" },
]
```

**Generate Changelog:**
```bash
# Generate changelog
git-cliff --output CHANGELOG.md

# Update changelog for specific version
git-cliff --tag v1.0.0 --output CHANGELOG.md
```

### 11.4 Docker Image Tagging

**Tagging Strategy:**
- `latest` - Latest development
- `v1.0.0` - Specific version
- `v1.0.0-abc1234` - Version with commit hash

**Build Commands:**
```bash
# Build and tag image
docker build -t dating-microservices-api-gateway:v1.0.0 .

# Push to registry
docker push ghcr.io/username/dating-microservices-api-gateway:v1.0.0
```

### 11.5 Release Automation

**Release Workflow:**
```yaml
name: Release
on:
  push:
    tags:
      - 'v*'
jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Generate changelog
        run: git-cliff --output CHANGELOG.md
      - name: Create Release
        uses: actions/create-release@v1
        with:
          tag_name: ${{ github.ref }}
          release_name: Release ${{ github.ref }}
          body_path: CHANGELOG.md
```

### 11.6 GitHub Container Registry

**Registry Configuration:**
```yaml
# Build and push to GHCR
- name: Build and push
  uses: docker/build-push-action@v4
  with:
    context: .
    push: true
    tags: |
      ghcr.io/${{ github.repository }}/api-gateway:${{ github.ref_name }}
      ghcr.io/${{ github.repository }}/api-gateway:latest
```

---

## 12. SECURITY & JWT

### 12.1 JWT Security Policy

**JWT Configuration:**
```yaml
# JWT Configuration
JWT_SECRET: "base64-encoded-256-bit-secret"
JWT_ALGORITHM: "HS256"
JWT_ACCESS_TOKEN_EXPIRE_MINUTES: 15
JWT_REFRESH_TOKEN_EXPIRE_DAYS: 7
JWT_ISSUER: "dating-app"
JWT_AUDIENCE: "dating-users"
```

**Token Structure:**
```json
{
  "header": {
    "alg": "HS256",
    "typ": "JWT"
  },
  "payload": {
    "sub": "user_id",
    "iss": "dating-app",
    "aud": "dating-users",
    "iat": 1640995200,
    "exp": 1640996100,
    "type": "access|refresh",
    "scope": "user|admin"
  }
}
```

### 12.2 SLO Requirements

**Performance Targets:**
| Metric | Target | Measurement |
|--------|--------|-------------|
| JWT Generation | < 50ms | 95th percentile |
| JWT Validation | < 10ms | 95th percentile |
| Refresh Token Flow | < 150ms | 95th percentile |
| Login Response | < 200ms | 95th percentile |
| Token Revocation | < 100ms | 95th percentile |

**Availability Targets:**
| Service | Target | Measurement |
|---------|--------|-------------|
| Auth Service | 99.9% | Monthly uptime |
| JWT Validation | 99.95% | Success rate |
| Token Refresh | 99.9% | Success rate |

### 12.3 Secret Rotation Procedures

**Rotation Schedule:**
- JWT_SECRET: Rotate every 90 days
- Emergency rotation: Within 24 hours of suspected compromise
- Planned rotation: First Sunday of each quarter

**Rotation Process:**
```bash
#!/bin/bash
# Generate new JWT secret
NEW_JWT_SECRET=$(python3 -c "import secrets; print(secrets.token_urlsafe(32))")
echo "New JWT secret: $NEW_JWT_SECRET"

# Store in secure location
echo "$NEW_JWT_SECRET" > /secure/jwt-secret-new.txt
chmod 600 /secure/jwt-secret-new.txt
```

**Gradual Rollout:**
```yaml
# Phase 1: Deploy with both old and new secrets
environment:
  JWT_SECRET_OLD: ${JWT_SECRET}
  JWT_SECRET_NEW: ${NEW_JWT_SECRET}

# Phase 2: Monitor for errors
# Phase 3: Remove old secret after 24 hours
```

### 12.4 Security Monitoring

**Metrics to Track:**
- JWT generation time
- JWT validation time
- Authentication failures
- Rate limiting triggers
- Token revocation events

**Alerting Rules:**
```yaml
groups:
  - name: jwt-security
    rules:
      - alert: HighJWTErrorRate
        expr: rate(jwt_errors_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High JWT error rate detected
      
      - alert: JWTGenerationSlow
        expr: histogram_quantile(0.95, jwt_generation_duration_seconds) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: JWT generation is slow
```

### 12.5 Emergency Response

**Security Incident Response:**
1. **Immediate Actions:**
   - Rotate all secrets immediately
   - Revoke all active tokens
   - Enable additional logging
   - Isolate affected systems

2. **Investigation:**
   - Analyze security logs
   - Identify attack vectors
   - Assess data exposure
   - Document findings

3. **Recovery:**
   - Update security policies
   - Implement additional controls
   - Notify stakeholders
   - Conduct post-incident review

**Emergency Rotation Script:**
```bash
#!/bin/bash
# Emergency JWT secret rotation
echo "EMERGENCY: Rotating JWT secret due to security incident"

# Generate new secret
NEW_SECRET=$(python3 -c "import secrets; print(secrets.token_urlsafe(32))")

# Update all services
docker compose exec auth-service sh -c "echo JWT_SECRET=$NEW_SECRET >> /app/.env"
docker compose exec api-gateway sh -c "echo JWT_SECRET=$NEW_SECRET >> /app/.env"

# Restart services
docker compose restart auth-service api-gateway

# Verify rotation
curl -H "Authorization: Bearer $OLD_TOKEN" http://localhost:8080/api/v1/auth/verify
# Should return 401 Unauthorized
```

---

## 13. OBSERVABILITY & MONITORING

### 13.1 Logging Standards (Structured JSON)

**Log Format:**
```json
{
  "timestamp": "2025-01-24T10:30:00Z",
  "level": "INFO",
  "logger": "service-name",
  "message": "Operation completed",
  "service_name": "auth-service",
  "request_id": "req-123",
  "user_id": 12345,
  "duration_ms": 150
}
```

**Log Levels:**
- DEBUG: Detailed information for debugging
- INFO: General information about operation
- WARNING: Something unexpected happened
- ERROR: Error occurred but service continues
- CRITICAL: Serious error, service may stop

### 13.2 Metrics Patterns (Prometheus)

**Counter Metrics:**
```python
from prometheus_client import Counter

request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)
```

**Histogram Metrics:**
```python
from prometheus_client import Histogram

request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)
```

### 13.3 Distributed Tracing (W3C Trace Context)

**Trace Headers:**
```python
# Extract trace context
traceparent = request.headers.get('traceparent')
tracestate = request.headers.get('tracestate')

# Propagate to downstream services
headers = {
    'traceparent': traceparent,
    'tracestate': tracestate
}
```

### 13.4 Health & Readiness Probes

**Health Check Endpoint:**
```python
async def health_check(request):
    return web.json_response({
        'status': 'healthy',
        'timestamp': datetime.utcnow().isoformat(),
        'version': '1.0.0'
    })
```

**Readiness Check:**
```python
async def readiness_check(request):
    # Check database connectivity
    # Check external dependencies
    # Return ready status
```

### 13.5 Grafana Dashboards

**Dashboard Metrics:**
- Request rate and duration
- Error rates by service
- Database connection pool
- Memory and CPU usage
- Custom business metrics

### 13.6 Alert Configuration

**Alert Rules:**
```yaml
groups:
  - name: dating-app
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High error rate detected
```

---

## 14. ARCHITECTURE & SYSTEM DESIGN

### 14.1 Microservices Architecture

**Service Dependencies:**
```
telegram-bot → api-gateway → auth-service
                    ↓
              profile-service
                    ↓
              discovery-service
                    ↓
              chat-service
```

**Data Flow:**
1. User interacts with Telegram bot
2. Bot sends requests to API Gateway
3. Gateway routes to appropriate service
4. Service processes request
5. Response sent back through gateway

### 14.2 Service Dependencies

**Core Services:**
- `auth-service`: Authentication and authorization
- `profile-service`: User profiles and preferences
- `discovery-service`: Matching algorithm
- `chat-service`: Messaging functionality
- `media-service`: File upload and processing

**Supporting Services:**
- `admin-service`: Admin panel and moderation
- `notification-service`: Push notifications
- `data-service`: Centralized data access

### 14.3 Database Schema Design

**Core Tables:**
- `users`: User accounts and authentication
- `profiles`: User profile information
- `photos`: User photos and media
- `interactions`: Swipe interactions
- `matches`: User matches
- `messages`: Chat messages
- `conversations`: Chat conversations

### 14.4 Message Queue Patterns (RabbitMQ)

**Queue Configuration:**
```python
# Notification queue
await channel.queue_declare('notifications', durable=True)

# Match notification
await channel.basic_publish(
    exchange='',
    routing_key='notifications',
    body=json.dumps({
        'type': 'match',
        'user_id': user_id,
        'match_id': match_id
    })
)
```

### 14.5 Cache Strategy

**Redis Caching:**
- User sessions: 24 hours
- Profile data: 1 hour
- Discovery results: 30 minutes
- Chat messages: 7 days

**Cache Keys:**
```
user:session:{user_id}
profile:{user_id}
discovery:{user_id}:{location}
chat:{conversation_id}:messages
```

---

## 15. TROUBLESHOOTING & DIAGNOSTICS

### 15.1 6-Phase Diagnostic Methodology

**Phase 1: Service Health**
```bash
# Check container status
docker compose ps

# Check service health
curl http://localhost:8080/health
```

**Phase 2: Database Connectivity**
```bash
# Test database connection
docker compose exec db psql -U dating -d dating -c "SELECT 1"

# Check migration status
docker compose exec telegram-bot alembic current
```

**Phase 3: Network Connectivity**
```bash
# Test internal network
docker compose exec api-gateway ping auth-service

# Test external connectivity
curl -f https://dating.serge.cc/health
```

**Phase 4: Log Analysis**
```bash
# Check service logs
docker compose logs telegram-bot --tail=50

# Check for errors
docker compose logs | grep ERROR
```

**Phase 5: Resource Usage**
```bash
# Check resource usage
docker stats

# Check disk space
df -h
```

**Phase 6: Configuration Validation**
```bash
# Validate configuration
docker compose config

# Check environment variables
docker compose exec telegram-bot env | grep -E "(POSTGRES|JWT|BOT)"
```

### 15.2 Common Problem Patterns

**Migration Issues:**
- Symptom: `KeyError: 'revision_id'`
- Solution: Check migration chain with `alembic check`
- Fix: Use `alembic merge` for conflicts

**Docker Permission Issues:**
- Symptom: `setgid(101) failed (1: Operation not permitted)`
- Solution: Add appropriate capabilities or run as root
- Fix: Update docker-compose.yml with correct capabilities

**Network Connectivity:**
- Symptom: `Temporary failure in name resolution`
- Solution: Check Docker networks and DNS configuration
- Fix: Ensure services are on correct networks

### 15.3 Diagnostic Commands Library

**Container Management:**
```bash
# List all containers
docker compose ps

# Check container logs
docker compose logs <service>

# Execute command in container
docker compose exec <service> <command>

# Restart service
docker compose restart <service>
```

**Database Diagnostics:**
```bash
# Connect to database
docker compose exec db psql -U dating -d dating

# Check migration status
docker compose exec telegram-bot alembic current

# Show migration history
docker compose exec telegram-bot alembic history
```

**Network Diagnostics:**
```bash
# Test internal connectivity
docker compose exec api-gateway curl http://auth-service:8081/health

# Check network configuration
docker network ls
docker network inspect dating-microservices_default
```

### 15.4 Emergency Procedures

**Service Recovery:**
```bash
# Restart all services
docker compose down && docker compose up -d

# Restart specific service
docker compose restart <service>

# Rebuild and restart
docker compose build <service> && docker compose up -d <service>
```

**Database Recovery:**
```bash
# Rollback migration
docker compose exec telegram-bot alembic downgrade -1

# Reset to specific migration
docker compose exec telegram-bot alembic stamp <revision>

# Restore from backup
docker compose exec -T db psql -U dating -d dating < backup.sql
```

---

## 16. CURSOR AI SPECIFIC GUIDANCE

### 16.1 Task Planning & TODO Management

**TODO Creation:**
- Use `todo_write` tool for task management
- Set appropriate status: `pending`, `in_progress`, `completed`, `cancelled`
- Provide clear, actionable task descriptions
- Update status in real-time

**Task Prioritization:**
- CRITICAL: System-breaking issues
- HIGH: Feature development
- MEDIUM: Improvements
- LOW: Nice-to-have features

### 16.2 File Reading & Editing Patterns

**File Reading:**
- Use `read_file` for complete file content
- Use `offset` and `limit` for large files
- Read multiple files in parallel when possible

**File Editing:**
- Use `search_replace` for precise changes
- Use `MultiEdit` for multiple changes to same file
- Use `write` for new files
- Always verify changes with `read_file`

### 16.3 Tool Selection Guidelines

**Code Analysis:**
- `codebase_search`: Semantic code search
- `grep`: Exact string/regex search
- `read_file`: File content analysis

**File Operations:**
- `search_replace`: Single precise edits
- `MultiEdit`: Multiple edits to same file
- `write`: New file creation
- `delete_file`: File removal

**System Operations:**
- `run_terminal_cmd`: Command execution
- `list_dir`: Directory listing
- `glob_file_search`: File pattern search

### 16.4 Communication Style

**Response Format:**
- Use clear, structured responses
- Include code examples in markdown blocks
- Provide step-by-step instructions
- Include error handling and validation

**Error Handling:**
- Acknowledge errors immediately
- Provide clear error descriptions
- Suggest specific solutions
- Follow up on error resolution

**Progress Updates:**
- Update TODO status in real-time
- Provide status summaries
- Include next steps
- Ask for clarification when needed

---

## CRITICAL REMINDERS

1. **Code Synchronization**: ALWAYS sync Local ↔ GitHub ↔ Server
2. **Migration Safety**: Only one service with RUN_DB_MIGRATIONS=true
3. **Docker Security**: Use pinned images, non-root users, security options
4. **Testing**: Run tests before deployment
5. **Documentation**: Keep rules updated and accurate
6. **Monitoring**: Check service health after changes
7. **Rollback**: Always have rollback plan ready

---

## 13. OBSERVABILITY & MONITORING

### 13.1 Logging Standards (Structured JSON)

**Log Format:**
```json
{
  "timestamp": "2025-01-24T10:30:00Z",
  "level": "INFO",
  "logger": "service-name",
  "message": "Operation completed",
  "service_name": "auth-service",
  "request_id": "req-123",
  "user_id": 12345,
  "duration_ms": 150
}
```

**Log Levels:**
- DEBUG: Detailed information for debugging
- INFO: General information about operation
- WARNING: Something unexpected happened
- ERROR: Error occurred but service continues
- CRITICAL: Serious error, service may stop

### 13.2 Metrics Patterns (Prometheus)

**Counter Metrics:**
```python
from prometheus_client import Counter

request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)
```

**Histogram Metrics:**
```python
from prometheus_client import Histogram

request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)
```

### 13.3 Distributed Tracing (W3C Trace Context)

**Trace Headers:**
```python
# Extract trace context
traceparent = request.headers.get('traceparent')
tracestate = request.headers.get('tracestate')

# Propagate to downstream services
headers = {
    'traceparent': traceparent,
    'tracestate': tracestate
}
```

### 13.4 Health & Readiness Probes

**Health Check Endpoint:**
```python
async def health_check(request):
    return web.json_response({
        'status': 'healthy',
        'timestamp': datetime.utcnow().isoformat(),
        'version': '1.0.0'
    })
```

### 13.5 Grafana Dashboards

**Dashboard Metrics:**
- Request rate and duration
- Error rates by service
- Database connection pool
- Memory and CPU usage
- Custom business metrics

### 13.6 Alert Configuration

**Alert Rules:**
```yaml
groups:
  - name: dating-app
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High error rate detected
```

---

## 14. ARCHITECTURE & SYSTEM DESIGN

### 14.1 Microservices Architecture

**Service Dependencies:**
```
telegram-bot → api-gateway → auth-service
                    ↓
              profile-service
                    ↓
              discovery-service
                    ↓
              chat-service
```

**Data Flow:**
1. User interacts with Telegram bot
2. Bot sends requests to API Gateway
3. Gateway routes to appropriate service
4. Service processes request
5. Response sent back through gateway

### 14.2 Service Dependencies

**Core Services:**
- `auth-service`: Authentication and authorization
- `profile-service`: User profiles and preferences
- `discovery-service`: Matching algorithm
- `chat-service`: Messaging functionality
- `media-service`: File upload and processing

**Supporting Services:**
- `admin-service`: Admin panel and moderation
- `notification-service`: Push notifications
- `data-service`: Centralized data access

### 14.3 Database Schema Design

**Core Tables:**
- `users`: User accounts and authentication
- `profiles`: User profile information
- `photos`: User photos and media
- `interactions`: Swipe interactions
- `matches`: User matches
- `messages`: Chat messages
- `conversations`: Chat conversations

### 14.4 Message Queue Patterns (RabbitMQ)

**Queue Configuration:**
```python
# Notification queue
await channel.queue_declare('notifications', durable=True)

# Match notification
await channel.basic_publish(
    exchange='',
    routing_key='notifications',
    body=json.dumps({
        'type': 'match',
        'user_id': user_id,
        'match_id': match_id
    })
)
```

### 14.5 Cache Strategy

**Redis Caching:**
- User sessions: 24 hours
- Profile data: 1 hour
- Discovery results: 30 minutes
- Chat messages: 7 days

**Cache Keys:**
```
user:session:{user_id}
profile:{user_id}
discovery:{user_id}:{location}
chat:{conversation_id}:messages
```

---

## 15. TROUBLESHOOTING & DIAGNOSTICS

### 15.1 6-Phase Diagnostic Methodology

**Phase 1: Service Health**
```bash
# Check container status
docker compose ps

# Check service health
curl http://localhost:8080/health
```

**Phase 2: Database Connectivity**
```bash
# Test database connection
docker compose exec db psql -U dating -d dating -c "SELECT 1"

# Check migration status
docker compose exec telegram-bot alembic current
```

**Phase 3: Network Connectivity**
```bash
# Test internal network
docker compose exec api-gateway ping auth-service

# Test external connectivity
curl -f https://dating.serge.cc/health
```

**Phase 4: Log Analysis**
```bash
# Check service logs
docker compose logs telegram-bot --tail=50

# Check for errors
docker compose logs | grep ERROR
```

**Phase 5: Resource Usage**
```bash
# Check resource usage
docker stats

# Check disk space
df -h
```

**Phase 6: Configuration Validation**
```bash
# Validate configuration
docker compose config

# Check environment variables
docker compose exec telegram-bot env | grep -E "(POSTGRES|JWT|BOT)"
```

### 15.2 Common Problem Patterns

**Migration Issues:**
- Symptom: `KeyError: 'revision_id'`
- Solution: Check migration chain with `alembic check`
- Fix: Use `alembic merge` for conflicts

**Docker Permission Issues:**
- Symptom: `setgid(101) failed (1: Operation not permitted)`
- Solution: Add appropriate capabilities or run as non-root
- Fix: Update docker-compose.yml with correct capabilities

**Network Connectivity:**
- Symptom: `Temporary failure in name resolution`
- Solution: Check Docker networks and DNS configuration
- Fix: Ensure services are on correct networks

### 15.3 Diagnostic Commands Library

**Container Management:**
```bash
# List all containers
docker compose ps

# Check container logs
docker compose logs <service>

# Execute command in container
docker compose exec <service> <command>

# Restart service
docker compose restart <service>
```

**Database Diagnostics:**
```bash
# Connect to database
docker compose exec db psql -U dating -d dating

# Check migration status
docker compose exec telegram-bot alembic current

# Show migration history
docker compose exec telegram-bot alembic history
```

**Network Diagnostics:**
```bash
# Test internal connectivity
docker compose exec api-gateway curl http://auth-service:8081/health

# Check network configuration
docker network ls
docker network inspect dating-microservices_default
```

### 15.4 Emergency Procedures

**Service Recovery:**
```bash
# Restart all services
docker compose down && docker compose up -d

# Restart specific service
docker compose restart <service>

# Rebuild and restart
docker compose build <service> && docker compose up -d <service>
```

**Database Recovery:**
```bash
# Rollback migration
docker compose exec telegram-bot alembic downgrade -1

# Reset to specific migration
docker compose exec telegram-bot alembic stamp <revision>

# Restore from backup
docker compose exec -T db psql -U dating -d dating < backup.sql
```

---

## 16. CURSOR AI SPECIFIC GUIDANCE

### 16.1 Task Planning & TODO Management

**TODO Creation:**
- Use `todo_write` tool for task management
- Set appropriate status: `pending`, `in_progress`, `completed`, `cancelled`
- Provide clear, actionable task descriptions
- Update status in real-time

**Task Prioritization:**
- CRITICAL: System-breaking issues
- HIGH: Feature development
- MEDIUM: Improvements
- LOW: Nice-to-have features

### 16.2 File Reading & Editing Patterns

**File Reading:**
- Use `read_file` for complete file content
- Use `offset` and `limit` for large files
- Read multiple files in parallel when possible

**File Editing:**
- Use `search_replace` for precise changes
- Use `MultiEdit` for multiple changes to same file
- Use `write` for new files
- Always verify changes with `read_file`

### 16.3 Tool Selection Guidelines

**Code Analysis:**
- `codebase_search`: Semantic code search
- `grep`: Exact string/regex search
- `read_file`: File content analysis

**File Operations:**
- `search_replace`: Single precise edits
- `MultiEdit`: Multiple edits to same file
- `write`: New file creation
- `delete_file`: File removal

**System Operations:**
- `run_terminal_cmd`: Command execution
- `list_dir`: Directory listing
- `glob_file_search`: File pattern search

### 16.4 Communication Style

**Response Format:**
- Use clear, structured responses
- Include code examples in markdown blocks
- Provide step-by-step instructions
- Include error handling and validation

**Error Handling:**
- Acknowledge errors immediately
- Provide clear error descriptions
- Suggest specific solutions
- Follow up on error resolution

**Progress Updates:**
- Update TODO status in real-time
- Provide status summaries
- Include next steps
- Ask for clarification when needed

---

## CRITICAL REMINDERS

1. **Code Synchronization**: ALWAYS sync Local ↔ GitHub ↔ Server
2. **Migration Safety**: Only one service with RUN_DB_MIGRATIONS=true
3. **Docker Security**: Use pinned images, non-root users, security options
4. **Testing**: Run tests before deployment
5. **Documentation**: Keep rules updated and accurate
6. **Monitoring**: Check service health after changes
7. **Rollback**: Always have rollback plan ready

---

*Last Updated: 2025-01-24*
*Version: 2.0*
*Status: Active*
